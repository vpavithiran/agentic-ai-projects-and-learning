{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2c218cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I help you today?', additional_kwargs={'reasoning_content': 'We need to respond as ChatGPT. The user says \"hello\". Just greet.'}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 72, 'total_tokens': 108, 'completion_time': 0.077061118, 'prompt_time': 0.002746004, 'queue_time': 0.102879896, 'total_time': 0.079807122}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_82669fd91d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--58a1ac4c-cb06-48f6-b77d-835dd4284c86-0', usage_metadata={'input_tokens': 72, 'output_tokens': 36, 'total_tokens': 108})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model=\"openai/gpt-oss-120b\", api_key=groq_api_key)\n",
    "llm.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2aaa3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Literal, TypedDict\n",
    "from typing import Annotated, List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498ee4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Section(BaseModel):\n",
    "    name:str=Field(description=\"Name of the section of the report\")\n",
    "    description:str = Field(description=\"Brief Overview of the main topics and concepts of the section\")\n",
    "\n",
    "class Sections(BaseModel):\n",
    "    sections:List[Section]=Field(description=\"Sections of the report\")\n",
    "\n",
    "planner = llm.with_structured_output(Sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b99116ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    topic:str\n",
    "    sections: list[Section]\n",
    "    completed_sections: Annotated[\n",
    "        list, operator.add\n",
    "    ]\n",
    "    final_report: str\n",
    "\n",
    "class WorkerState(TypedDict):\n",
    "    section: Section\n",
    "    completed_sections: Annotated[list, operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73992f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orchestrator(state: State):\n",
    "    \"\"\"Orchestrator that generates a plan for the report\"\"\"\n",
    "\n",
    "    # Generate queries\n",
    "    report_sections = planner.invoke(\n",
    "        [\n",
    "            SystemMessage(content=\"Generate a plan for the report.\"),\n",
    "            HumanMessage(content=f\"Here is the report topic: {state['topic']}\"),\n",
    "        ]\n",
    "    )\n",
    "    print(\"Report_Sections: \", report_sections)\n",
    "    return {\"sections\":report_sections.sections}\n",
    "\n",
    "def llm_call(state:WorkerState):\n",
    "    \"\"\"Worker writes a section of the report\"\"\"\n",
    "    section = llm.invoke(\n",
    "        [\n",
    "            SystemMessage(content=\"Write a report section following the provided name and description. Include no preamble. Use markdown formatting\"),\n",
    "            HumanMessage(content=f\"Here is the section name: {state['section'].name} and description: {state['section'].description}\"\n",
    "                         ),\n",
    "        ]\n",
    "    )\n",
    "    return {\"completed_sections\": [section.content]}\n",
    "\n",
    "from langgraph.types import Send\n",
    "def assign_workers(state:State):\n",
    "    \"\"\"Assign a worker to each section in the plan\"\"\"\n",
    "    return [Send(\"llm_call\", {\"section\": s}) for s in state[\"sections\"]]\n",
    "\n",
    "def synthesizer(state: State):\n",
    "    \"\"\"Synthesize full report from sections\"\"\"\n",
    "    completed_sections = state[\"completed_sections\"]\n",
    "    completed_report_sections = \"\\n\\n---\\n\\n\".join(completed_sections)\n",
    "    completed_report_sections =  completed_report_sections\n",
    "    return {\"final_report\": completed_report_sections}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9623197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import display, Image\n",
    "# Build workflow\n",
    "\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "orchestrator_worker_builder = StateGraph(State)\n",
    "\n",
    "# Add the nodes\n",
    "orchestrator_worker_builder.add_node(\"orchestrator\", orchestrator)\n",
    "orchestrator_worker_builder.add_node(\"llm_call\", llm_call)\n",
    "orchestrator_worker_builder.add_node(\"synthesizer\", synthesizer)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "orchestrator_worker_builder.add_edge(START, \"orchestrator\")\n",
    "orchestrator_worker_builder.add_conditional_edges(\n",
    "    \"orchestrator\", assign_workers, [\"llm_call\"]\n",
    ")\n",
    "\n",
    "orchestrator_worker_builder.add_edge(\"llm_call\", \"synthesizer\")\n",
    "orchestrator_worker_builder.add_edge(\"synthesizer\", END)\n",
    "\n",
    "# Compile the workflow\n",
    "orchestrator_worker = orchestrator_worker_builder.compile()\n",
    "\n",
    "# Show the workflow\n",
    "display(Image(orchestrator_worker.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee31e0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report_Sections:  sections=[Section(name='Executive Summary', description=\"A concise overview of the report's purpose, key findings, and recommendations regarding deep learning technologies and their impact.\"), Section(name='Introduction to Deep Learning', description='Definition of deep learning, its relationship to machine learning and AI, historical evolution, and why it matters today.'), Section(name='Fundamental Concepts', description='Explanation of neural networks, layers, activation functions, loss functions, backpropagation, and optimization algorithms.'), Section(name='Architectures and Models', description='Survey of major deep learning architectures such as CNNs, RNNs, LSTMs, Transformers, GANs, and emerging hybrid models.'), Section(name='Training Techniques and Best Practices', description='Discussion of data preparation, regularization, transfer learning, hyper‑parameter tuning, distributed training, and model evaluation metrics.'), Section(name='Hardware and Software Ecosystem', description='Overview of GPUs, TPUs, ASICs, cloud services, and popular frameworks (TensorFlow, PyTorch, JAX) that enable deep learning development.'), Section(name='Applications Across Industries', description='Case studies illustrating deep learning use‑cases in computer vision, natural language processing, healthcare, finance, autonomous systems, and recommendation engines.'), Section(name='Challenges and Limitations', description='Analysis of data requirements, interpretability, bias, robustness, energy consumption, and ethical concerns.'), Section(name='Future Directions', description='Emerging research trends such as self‑supervised learning, neuromorphic computing, model compression, and regulatory frameworks.'), Section(name='Conclusion and Recommendations', description='Summarizes insights, highlights strategic actions for stakeholders, and outlines steps for continued learning and adoption.'), Section(name='References', description='Comprehensive list of academic papers, books, industry reports, and online resources cited throughout the report.')]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Executive Summary\n",
       "\n",
       "This report examines the rapid evolution of deep learning technologies, evaluates their transformative impact across industries, and outlines strategic recommendations for organizations seeking to leverage these advances.\n",
       "\n",
       "### Purpose\n",
       "- **Scope:** Assess the current state of deep learning (DL) research, commercial adoption, and emerging trends.\n",
       "- **Goal:** Provide decision‑makers with actionable insights on how DL can enhance productivity, innovation, and competitive advantage while addressing associated risks.\n",
       "\n",
       "### Key Findings\n",
       "| Area | Findings |\n",
       "|------|----------|\n",
       "| **Performance Gains** | DL models now achieve superhuman accuracy in vision, speech, and language tasks, reducing error rates by 30‑80 % compared to traditional machine‑learning approaches. |\n",
       "| **Industry Adoption** | • **Healthcare:** AI‑driven diagnostics cut imaging review times by up to 70 % and improve early disease detection.<br>• **Finance:** Fraud detection systems using DL lower false‑positive rates by 40 % and enable real‑time risk scoring.<br>• **Manufacturing:** Predictive maintenance models reduce unplanned downtime by 25‑35 %. |\n",
       "| **Economic Impact** | Global DL market projected to reach **$250 B** by 2030, driven by AI‑enabled products and services. |\n",
       "| **Talent Gap** | Shortage of skilled DL engineers remains a bottleneck; 62 % of firms report difficulty filling positions. |\n",
       "| **Ethical & Regulatory Concerns** | Bias, opacity, and data privacy pose compliance challenges; emerging regulations (e.g., EU AI Act) will impose stricter transparency and accountability standards. |\n",
       "| **Infrastructure Trends** | Edge AI and model compression are accelerating deployment in low‑latency, resource‑constrained environments. |\n",
       "\n",
       "### Recommendations\n",
       "1. **Strategic Investment in Talent & Training**  \n",
       "   - Establish internal DL bootcamps and partner with academic institutions to build a pipeline of qualified engineers and data scientists.\n",
       "\n",
       "2. **Adopt a Modular AI Architecture**  \n",
       "   - Deploy reusable model components (e.g., pre‑trained transformers, vision encoders) to accelerate time‑to‑value and reduce development costs.\n",
       "\n",
       "3. **Implement Robust Governance Frameworks**  \n",
       "   - Introduce model‑card documentation, bias audits, and continuous monitoring to satisfy regulatory requirements and maintain stakeholder trust.\n",
       "\n",
       "4. **Leverage Edge and Federated Learning**  \n",
       "   - Move inference to the edge for latency‑sensitive applications and use federated learning to protect data privacy while benefiting from distributed training.\n",
       "\n",
       "5. **Prioritize High‑Impact Use Cases**  \n",
       "   - Focus initial DL projects on domains with clear ROI—such as predictive maintenance, automated quality inspection, and personalized customer experiences—before scaling to broader enterprise functions.\n",
       "\n",
       "By aligning technology adoption with these recommendations, organizations can harness deep learning’s disruptive potential while mitigating risks, ensuring sustainable competitive advantage in the AI‑driven economy.\n",
       "\n",
       "---\n",
       "\n",
       "## Introduction to Deep Learning\n",
       "\n",
       "**Definition**  \n",
       "Deep learning is a subset of machine learning that employs artificial neural networks with multiple layers—often referred to as *deep* neural networks—to automatically learn hierarchical representations of data. Unlike traditional machine‑learning algorithms that rely heavily on handcrafted features, deep learning models discover relevant features directly from raw inputs such as images, text, or audio.\n",
       "\n",
       "**Relationship to Machine Learning and AI**  \n",
       "- **Artificial Intelligence (AI):** The broad discipline concerned with building systems that can perform tasks that normally require human intelligence (reasoning, perception, decision‑making).  \n",
       "- **Machine Learning (ML):** A subfield of AI that focuses on algorithms that improve performance through experience (data).  \n",
       "- **Deep Learning (DL):** A specialized branch of ML that uses deep neural architectures to model complex, non‑linear relationships. In essence:  \n",
       "  \\[\n",
       "  \\text{AI} \\supset \\text{ML} \\supset \\text{DL}\n",
       "  \\]\n",
       "\n",
       "**Historical Evolution**  \n",
       "\n",
       "| Era | Milestones | Impact |\n",
       "|-----|------------|--------|\n",
       "| **1940s–1960s** | Early perceptron models (Rosenblatt, 1958) | First attempts at learning via weighted connections. |\n",
       "| **1980s** | Backpropagation algorithm (Rumelhart, Hinton, Williams, 1986) | Enabled training of multi‑layer networks, reviving interest. |\n",
       "| **1990s** | Convolutional Neural Networks (LeCun et al., 1998) for digit recognition | Demonstrated spatial invariance for vision tasks. |\n",
       "| **2006–2012** | *Deep* learning renaissance (Hinton’s “deep belief nets”, 2006; AlexNet, 2012) | GPU acceleration and large datasets made training deep nets feasible, achieving breakthrough performance on ImageNet. |\n",
       "| **2014–2018** | Recurrent & attention models (LSTM, 1997; Transformers, 2017) | Extended deep learning to sequential data, natural language processing, and speech. |\n",
       "| **2019–present** | Foundation models (GPT‑3, BERT, DALL·E) and multimodal architectures | Scale‑up to billions of parameters, enabling few‑shot learning and cross‑modal generation. |\n",
       "\n",
       "**Why Deep Learning Matters Today**  \n",
       "\n",
       "1. **State‑of‑the‑art performance** – Across vision, speech, language, and reinforcement learning, deep models consistently outperform traditional methods.  \n",
       "2. **Automation of feature engineering** – Reduces reliance on domain experts, accelerating product development cycles.  \n",
       "3. **Scalability** – Modern hardware (GPUs, TPUs) and distributed training frameworks allow models to ingest massive datasets, unlocking insights from big data.  \n",
       "4. **Broad applicability** – From medical imaging diagnostics and autonomous vehicles to personalized recommendation systems and scientific discovery, deep learning drives innovation across industries.  \n",
       "5. **Foundation for emerging AI systems** – Large pre‑trained models serve as universal “knowledge bases,” enabling rapid adaptation to new tasks with minimal data.\n",
       "\n",
       "In sum, deep learning has transformed AI from a research curiosity into a practical engine powering today’s most impactful technologies.\n",
       "\n",
       "---\n",
       "\n",
       "## Fundamental Concepts\n",
       "\n",
       "### Neural Networks\n",
       "A neural network is a computational model inspired by the biological brain, composed of interconnected **neurons** (or nodes) that transform input data into desired outputs. Networks are typically organized in a **feed‑forward** manner, where information flows from the input layer through hidden layers to the output layer.\n",
       "\n",
       "### Layers\n",
       "| Layer Type | Purpose | Typical Components |\n",
       "|------------|---------|--------------------|\n",
       "| **Input Layer** | Receives raw data | No parameters; size matches feature dimension |\n",
       "| **Hidden Layer(s)** | Learns hierarchical representations | Linear transformation (weights & bias) + activation |\n",
       "| **Output Layer** | Produces final predictions | Activation depends on task (e.g., softmax for classification) |\n",
       "\n",
       "### Activation Functions\n",
       "Non‑linear functions applied element‑wise after each linear transformation, enabling the network to model complex patterns.\n",
       "\n",
       "| Function | Formula | Range | Typical Use |\n",
       "|----------|---------|-------|-------------|\n",
       "| **ReLU** (Rectified Linear Unit) | `f(x)=max(0, x)` | `[0, ∞)` | Hidden layers; fast convergence |\n",
       "| **Sigmoid** | `σ(x)=1/(1+e^{-x})` | `(0,1)` | Binary classification output |\n",
       "| **Tanh** | `tanh(x)= (e^{x}-e^{-x})/(e^{x}+e^{-x})` | `(-1,1)` | Hidden layers when zero‑centered output is beneficial |\n",
       "| **Softmax** | `softmax_i(z)=e^{z_i}/∑_j e^{z_j}` | Probability simplex | Multi‑class classification output |\n",
       "\n",
       "### Loss Functions\n",
       "Quantify the discrepancy between the network’s predictions and the true targets; the optimizer seeks to minimize this value.\n",
       "\n",
       "| Task | Loss Function | Formula |\n",
       "|------|---------------|---------|\n",
       "| **Regression** | Mean Squared Error (MSE) | `L = (1/N)∑(ŷ_i - y_i)^2` |\n",
       "| **Binary Classification** | Binary Cross‑Entropy | `L = -(1/N)∑[y_i log(ŷ_i) + (1-y_i)log(1-ŷ_i)]` |\n",
       "| **Multi‑class Classification** | Categorical Cross‑Entropy | `L = -(1/N)∑∑ y_{i,c} log(ŷ_{i,c})` |\n",
       "| **Ranking / Embedding** | Contrastive / Triplet Loss | Depends on pairwise distances |\n",
       "\n",
       "### Backpropagation\n",
       "An efficient algorithm for computing gradients of the loss with respect to every weight in the network:\n",
       "\n",
       "1. **Forward Pass** – Compute activations layer‑by‑layer to obtain predictions and loss.\n",
       "2. **Backward Pass** – Apply the chain rule recursively from the output layer back to the input layer:\n",
       "   - Compute gradient of loss w.r.t. output activation.\n",
       "   - Propagate gradients through each layer’s activation derivative and linear transformation.\n",
       "3. **Parameter Update** – Use the obtained gradients to adjust weights (and biases) via an optimization algorithm.\n",
       "\n",
       "Mathematically, for a weight \\(W^{(l)}\\) in layer \\(l\\):\n",
       "\\[\n",
       "\\frac{\\partial L}{\\partial W^{(l)}} = \\delta^{(l)} \\cdot a^{(l-1)^\\top},\n",
       "\\]\n",
       "where \\(\\delta^{(l)}\\) is the error term for layer \\(l\\) and \\(a^{(l-1)}\\) are activations from the previous layer.\n",
       "\n",
       "### Optimization Algorithms\n",
       "Methods that use the gradients from backpropagation to iteratively update parameters.\n",
       "\n",
       "| Algorithm | Update Rule | Key Characteristics |\n",
       "|-----------|-------------|----------------------|\n",
       "| **Stochastic Gradient Descent (SGD)** | \\(θ_{t+1}=θ_t - η∇_θ L\\) | Simple; requires careful learning‑rate tuning |\n",
       "| **Momentum SGD** | \\(v_{t+1}=μv_t - η∇_θ L,\\; θ_{t+1}=θ_t+v_{t+1}\\) | Accelerates convergence, dampens oscillations |\n",
       "| **AdaGrad** | \\(θ_{t+1}=θ_t - \\frac{η}{\\sqrt{G_t + ε}}∇_θ L\\) | Adapts learning rate per parameter; good for sparse data |\n",
       "| **RMSprop** | Uses exponentially decaying average of squared gradients | Addresses AdaGrad’s aggressive decay |\n",
       "| **Adam** (Adaptive Moment Estimation) | Combines momentum and RMSprop: <br> \\(m_t = β_1 m_{t-1} + (1-β_1)∇_θ L\\) <br> \\(v_t = β_2 v_{t-1} + (1-β_2)(∇_θ L)^2\\) <br> \\(θ_{t+1}=θ_t - η \\frac{m_t}{\\sqrt{v_t}+ε}\\) | Widely used; robust to hyper‑parameter choices |\n",
       "\n",
       "These components—network architecture, activation choices, loss formulation, backpropagation, and optimization—constitute the foundational toolkit for designing and training modern neural networks.\n",
       "\n",
       "---\n",
       "\n",
       "## Architectures and Models\n",
       "\n",
       "### 1. Convolutional Neural Networks (CNNs)\n",
       "\n",
       "| Aspect | Details |\n",
       "|--------|---------|\n",
       "| **Core Idea** | Local receptive fields and weight sharing to capture spatial hierarchies in grid‑like data (e.g., images). |\n",
       "| **Key Components** | Convolutional layers, pooling (max/average), activation functions (ReLU, LeakyReLU), batch normalization, fully‑connected readout. |\n",
       "| **Representative Variants** | LeNet‑5, AlexNet, VGG, ResNet (skip connections), DenseNet (dense connectivity), EfficientNet (compound scaling). |\n",
       "| **Typical Applications** | Image classification, object detection (YOLO, Faster‑RCNN), semantic segmentation (U‑Net, DeepLab), video frame analysis, medical imaging. |\n",
       "| **Strengths** | Parameter efficiency, translation invariance, strong performance on visual tasks. |\n",
       "| **Limitations** | Limited ability to model long‑range dependencies; requires large labeled datasets for deep variants. |\n",
       "\n",
       "---\n",
       "\n",
       "### 2. Recurrent Neural Networks (RNNs)\n",
       "\n",
       "| Aspect | Details |\n",
       "|--------|---------|\n",
       "| **Core Idea** | Sequential processing with hidden state that evolves over time, enabling temporal context retention. |\n",
       "| **Key Components** | Recurrent cell (simple RNN), hidden state vector, back‑propagation through time (BPTT). |\n",
       "| **Representative Variants** | Elman RNN, GRU (Gated Recurrent Unit), bidirectional RNNs. |\n",
       "| **Typical Applications** | Language modeling, speech recognition, time‑series forecasting, video captioning. |\n",
       "| **Strengths** | Natural fit for variable‑length sequences; can capture short‑term dependencies. |\n",
       "| **Limitations** | Vanishing/exploding gradients hinder learning of long‑range dependencies; computationally intensive for long sequences. |\n",
       "\n",
       "---\n",
       "\n",
       "### 3. Long Short‑Term Memory (LSTM)\n",
       "\n",
       "| Aspect | Details |\n",
       "|--------|---------|\n",
       "| **Core Idea** | Augmented RNN cell with gated mechanisms (input, forget, output) to preserve information over long horizons. |\n",
       "| **Key Components** | Cell state, three gates, peephole connections (optional). |\n",
       "| **Representative Variants** | Standard LSTM, stacked LSTM, bidirectional LSTM, attention‑augmented LSTM. |\n",
       "| **Typical Applications** | Machine translation, speech synthesis, video activity recognition, anomaly detection in sensor streams. |\n",
       "| **Strengths** | Mitigates vanishing gradient problem; excels at modeling long‑term temporal patterns. |\n",
       "| **Limitations** | Higher computational cost than simple RNNs; still outperformed by attention‑based models on many NLP tasks. |\n",
       "\n",
       "---\n",
       "\n",
       "### 4. Transformers\n",
       "\n",
       "| Aspect | Details |\n",
       "|--------|---------|\n",
       "| **Core Idea** | Self‑attention mechanism replaces recurrence, allowing direct modeling of pairwise token interactions regardless of distance. |\n",
       "| **Key Components** | Multi‑head self‑attention, positional encodings, feed‑forward layers, layer normalization, residual connections. |\n",
       "| **Representative Architectures** | Original Transformer (Vaswani et al., 2017), BERT, GPT series, T5, Vision Transformer (ViT), Swin Transformer. |\n",
       "| **Typical Applications** | Natural language understanding/generation, code synthesis, protein folding (AlphaFold), image classification, multimodal tasks. |\n",
       "| **Strengths** | Parallelizable training, excellent scalability, state‑of‑the‑art performance across modalities. |\n",
       "| **Limitations** | Quadratic attention cost w.r.t. sequence length; large memory footprint; requires massive pre‑training data. |\n",
       "\n",
       "---\n",
       "\n",
       "### 5. Generative Adversarial Networks (GANs)\n",
       "\n",
       "| Aspect | Details |\n",
       "|--------|---------|\n",
       "| **Core Idea** | Two networks—a generator **G** and a discriminator **D**—play a minimax game; **G** learns to synthesize realistic data, **D** learns to distinguish real from fake. |\n",
       "| **Key Components** | Generator, discriminator, adversarial loss (e.g., Wasserstein, hinge), optional auxiliary losses (pixel‑wise, perceptual). |\n",
       "| **Representative Variants** | DCGAN, Conditional GAN (cGAN), CycleGAN, StyleGAN/StyleGAN2/StyleGAN3, BigGAN, SAGAN (self‑attention). |\n",
       "| **Typical Applications** | Image synthesis, super‑resolution, style transfer, data augmentation, video generation, audio synthesis. |\n",
       "| **Strengths** | Produces high‑fidelity, diverse samples; flexible conditioning mechanisms. |\n",
       "| **Limitations** | Training instability, mode collapse, sensitivity to hyper‑parameters, lack of explicit likelihood. |\n",
       "\n",
       "---\n",
       "\n",
       "### 6. Emerging Hybrid Models\n",
       "\n",
       "| Hybrid Model | Composition | Motivation & Advantages | Example Use‑Cases |\n",
       "|--------------|-------------|------------------------|-------------------|\n",
       "| **CNN‑Transformer Hybrids** | Early convolutional stem + Transformer encoder/decoder | Leverages CNN’s locality and Transformer's global attention; reduces quadratic cost on high‑resolution inputs. | Vision Transformers (ViT‑Hybrid), Swin Transformer, ConvNeXt‑based backbones for detection. |\n",
       "| **RNN‑Attention Networks** | RNN (LSTM/GRU) layers feeding into self‑attention modules | Captures sequential dynamics while allowing flexible long‑range dependencies. | Speech‑to‑text models, video captioning pipelines. |\n",
       "| **GAN‑VAE Fusion** | VAE encoder‑decoder paired with adversarial discriminator | Improves sample quality (GAN) while retaining latent space interpretability (VAE). | High‑resolution image synthesis, controllable generation. |\n",
       "| **Diffusion‑Transformer Models** | Diffusion process guided by Transformer‑based denoising networks | Provides stable training and high‑quality generation, especially for complex modalities. | Text‑to‑image (e.g., DALL·E 2), audio generation. |\n",
       "| **Graph‑Neural‑Transformer (GNN‑Transformer)** | Graph convolutional layers feeding into Transformer attention | Merges relational inductive bias of GNNs with flexible attention for heterogeneous data. | Molecular property prediction, social network analysis. |\n",
       "| **Multimodal Fusion Architectures** | Separate modality‑specific encoders (CNN, RNN, Transformer) → cross‑modal attention or gating | Enables joint reasoning over vision, language, audio, and sensor streams. | Video‑question answering, autonomous driving perception stacks. |\n",
       "\n",
       "#### Trends and Research Directions\n",
       "- **Efficient Attention**: Linear‑complexity variants (Performer, Reformer, Longformer) aim to scale Transformers to ultra‑long sequences.\n",
       "- **Neural Architecture Search (NAS)**: Automated discovery of optimal hybrid topologies (e.g., EfficientNet‑B0, AutoFormer).\n",
       "- **Self‑Supervised Pre‑training**: Contrastive and masked modeling techniques are being applied across CNNs, Transformers, and hybrid pipelines.\n",
       "- **Robustness & Explainability**: Integration of attention visualizations, saliency maps, and causal inference to interpret model decisions.\n",
       "\n",
       "---\n",
       "\n",
       "### 7. Summary\n",
       "\n",
       "- **CNNs** dominate visual feature extraction through hierarchical, locality‑preserving filters.  \n",
       "- **RNNs** and **LSTMs** remain relevant for sequential data where explicit recurrence is beneficial, though they are increasingly supplanted by attention mechanisms.  \n",
       "- **Transformers** have become the de‑facto standard for both language and vision, offering unparalleled performance at the cost of computational resources.  \n",
       "- **GANs** continue to push the frontier of generative modeling, especially when paired with auxiliary objectives or hybridized with VAEs and diffusion processes.  \n",
       "- **Hybrid models** synthesize the strengths of the above architectures, addressing their individual limitations and enabling more versatile, scalable, and multimodal AI systems.  \n",
       "\n",
       "These architectures collectively form the backbone of modern deep learning research and applications, and their ongoing evolution drives the next wave of breakthroughs across domains.\n",
       "\n",
       "---\n",
       "\n",
       "## Training Techniques and Best Practices\n",
       "\n",
       "### 1. Data Preparation\n",
       "| Step | Description | Best‑Practice Tips |\n",
       "|------|-------------|--------------------|\n",
       "| **Data Collection** | Gather raw inputs from reliable sources, ensuring coverage of all target classes and edge cases. | • Use version‑controlled data pipelines.<br>• Document provenance and licensing. |\n",
       "| **Cleaning & Filtering** | Remove duplicates, corrupt records, and outliers; handle missing values. | • Apply deterministic scripts to guarantee reproducibility.<br>• Log statistics before/after cleaning. |\n",
       "| **Labeling & Annotation** | Assign ground‑truth labels, often via human annotators or semi‑automated tools. | • Implement inter‑annotator agreement checks (e.g., Cohen’s κ).<br>• Use active learning to focus labeling effort on uncertain samples. |\n",
       "| **Balancing & Sampling** | Mitigate class imbalance through oversampling, undersampling, or synthetic generation (SMOTE, GANs). | • Prefer class‑aware loss weighting over naive oversampling for large datasets. |\n",
       "| **Feature Engineering / Tokenization** | Convert raw data into model‑ready representations (e.g., TF‑IDF, embeddings, image augmentations). | • Standardize preprocessing (same tokenizers, image resize, normalization) across train/validation/test splits. |\n",
       "| **Data Splitting** | Partition data into training, validation, and test sets (commonly 70/15/15). | • Use stratified splits for classification tasks.<br>• Keep a hold‑out test set untouched until final evaluation. |\n",
       "\n",
       "### 2. Regularization\n",
       "| Technique | How It Works | When to Use |\n",
       "|-----------|--------------|-------------|\n",
       "| **L1 / L2 Weight Decay** | Adds a penalty proportional to the absolute (L1) or squared (L2) magnitude of weights to the loss. | L2 is default for most deep nets; L1 for inducing sparsity. |\n",
       "| **Dropout** | Randomly zeroes a fraction of activations during training. | Effective in fully‑connected and transformer layers; typical rates 0.1–0.5. |\n",
       "| **Batch / Layer Normalization** | Normalizes activations to reduce internal covariate shift, stabilizing gradients. | Essential for deep CNNs and Transformers; improves convergence speed. |\n",
       "| **Data Augmentation** | Generates synthetic variations (rotations, cropping, noise) on‑the‑fly. | Critical for vision and speech; can be combined with MixUp or CutMix. |\n",
       "| **Early Stopping** | Halts training when validation loss stops improving for *p* epochs. | Prevents over‑fitting when training budget is limited. |\n",
       "| **Label Smoothing** | Softens hard targets (e.g., 0/1) to a small probability (e.g., 0.1) for the non‑target class. | Helps calibrate confidence, especially for large‑scale classification. |\n",
       "\n",
       "### 3. Transfer Learning\n",
       "1. **Pre‑training** – Leverage a model trained on a large, generic dataset (e.g., ImageNet, BERT, CLIP).  \n",
       "2. **Feature Extraction** – Freeze the backbone and train only a lightweight head on the target task.  \n",
       "3. **Fine‑tuning** – Unfreeze selected layers (often the last few) and continue training with a reduced learning rate.  \n",
       "\n",
       "**Best Practices**\n",
       "- Match the source domain to the target as closely as possible (e.g., medical imaging → pre‑train on radiology datasets).  \n",
       "- Use **gradual unfreezing**: start with the head, then progressively unfreeze deeper layers.  \n",
       "- Apply **learning‑rate discrimination** (smaller LR for pretrained layers, larger LR for new layers).  \n",
       "- When fine‑tuning large language models, employ **parameter‑efficient adapters** (LoRA, prefix‑tuning) to reduce memory footprint.\n",
       "\n",
       "### 4. Hyper‑parameter Tuning\n",
       "| Parameter | Typical Search Space | Recommended Search Method |\n",
       "|-----------|----------------------|----------------------------|\n",
       "| Learning Rate | 1e‑5 – 1e‑2 (log‑scale) | Bayesian optimization (e.g., Optuna) |\n",
       "| Batch Size | 16 – 1024 (power‑of‑2) | Grid search for small ranges; scaling laws for large models |\n",
       "| Weight Decay | 0 – 1e‑2 (log‑scale) | Random search |\n",
       "| Dropout Rate | 0.0 – 0.7 | Manual sweep + early stopping |\n",
       "| Number of Layers / Width | Discrete (e.g., 12, 24, 36) | Evolutionary algorithms for architecture search |\n",
       "| Optimizer | Adam, AdamW, LAMB, RMSprop | Compare based on convergence speed & stability |\n",
       "\n",
       "**Practical Tips**\n",
       "- Use **learning‑rate warm‑up** (5–10% of total steps) to avoid divergence.  \n",
       "- Adopt **circular or cosine annealing** schedules for smoother convergence.  \n",
       "- Run **small‑scale proxy experiments** (reduced dataset, fewer epochs) to prune the search space before full‑scale runs.  \n",
       "- Record all trials in a **tracking system** (MLflow, Weights & Biases) to enable reproducibility.\n",
       "\n",
       "### 5. Distributed Training\n",
       "| Paradigm | Framework | Typical Use‑Case |\n",
       "|----------|-----------|------------------|\n",
       "| **Data Parallelism** | PyTorch DistributedDataParallel (DDP), TensorFlow MirroredStrategy | Scale batch size across GPUs/TPUs; most common. |\n",
       "| **Model Parallelism** | Mesh TensorFlow, DeepSpeed ZeRO‑3 | Very large models that exceed single‑device memory. |\n",
       "| **Pipeline Parallelism** | TorchPipe, Megatron‑LM | Split sequential layers across devices to improve throughput. |\n",
       "| **Hybrid (Data + Model)** | DeepSpeed, FairScale | Combine benefits for giant transformer‑style models. |\n",
       "\n",
       "**Key Practices**\n",
       "- **Gradient Accumulation** to emulate larger batch sizes when GPU memory is limited.  \n",
       "- **Synchronous vs. Asynchronous**: prefer synchronous SGD for deterministic convergence; asynchronous can be useful for heterogeneous clusters but may require extra variance reduction.  \n",
       "- **Communication Optimization**: enable NCCL/CollectiveOps, use mixed‑precision (FP16/BF16) to reduce bandwidth.  \n",
       "- **Checkpoint Sharding**: store checkpoints per rank to avoid I/O bottlenecks.  \n",
       "- **Fault Tolerance**: integrate checkpoint‑restart logic; use elastic training (e.g., PyTorch Elastic) for dynamic resource allocation.\n",
       "\n",
       "### 6. Model Evaluation Metrics\n",
       "| Task Type | Primary Metric(s) | Complementary Metrics |\n",
       "|-----------|-------------------|-----------------------|\n",
       "| **Classification** | Accuracy, Top‑k Accuracy | Precision, Recall, F1, ROC‑AUC, Confusion Matrix |\n",
       "| **Imbalanced Classification** | AUROC, AUPRC | Matthews Correlation Coefficient (MCC), Balanced Accuracy |\n",
       "| **Regression** | MSE / RMSE, MAE | R², Huber loss, Quantile loss |\n",
       "| **Object Detection** | mAP (IoU thresholds 0.5:0.95) | Recall@K, F1 per class |\n",
       "| **Segmentation** | IoU / Dice coefficient | Pixel Accuracy, Boundary F1 |\n",
       "| **Language Generation** | BLEU, ROUGE, METEOR | BERTScore, BLEURT, Human evaluation (fluency, relevance) |\n",
       "| **Ranking / Retrieval** | NDCG@k, MAP | Recall@k, Precision@k |\n",
       "| **Calibration** | Expected Calibration Error (ECE) | Brier Score, Reliability Diagram |\n",
       "\n",
       "**Evaluation Workflow**\n",
       "1. **Hold‑out Test Set** – Strictly unseen data; compute all primary metrics.  \n",
       "2. **Cross‑Validation** – For small datasets, use k‑fold CV to assess variance.  \n",
       "3. **Statistical Significance** – Apply paired bootstrap or permutation tests when comparing models.  \n",
       "4. **Error Analysis** – Inspect mis‑classifications, confusion matrices, or failure cases to guide further data or model improvements.  \n",
       "5. **Monitoring in Production** – Track drift (distribution shift) and degradation using online metrics (e.g., daily ECE, latency).  \n",
       "\n",
       "---  \n",
       "\n",
       "**Bottom‑Line Recommendations**\n",
       "- Start with a **robust data pipeline**; garbage in → garbage out cannot be fixed by sophisticated models.  \n",
       "- Apply **regularization early** (weight decay, dropout) and monitor validation loss for signs of over‑fitting.  \n",
       "- Leverage **transfer learning** whenever a suitable pretrained backbone exists; it reduces data requirements dramatically.  \n",
       "- Conduct **systematic hyper‑parameter searches** on a reduced proxy before scaling up.  \n",
       "- When scaling, adopt **data parallelism** first; move to model/pipeline parallelism only if model size dictates.  \n",
       "- Use **task‑specific metrics** plus calibration checks to ensure the model is both accurate and trustworthy.  \n",
       "\n",
       "Implementing these practices consistently yields models that train efficiently, generalize well, and can be safely deployed at scale.\n",
       "\n",
       "---\n",
       "\n",
       "## Hardware and Software Ecosystem\n",
       "\n",
       "### 1. Compute Accelerators  \n",
       "\n",
       "| Accelerator | Architecture | Typical Use‑Case | Key Advantages | Notable Providers |\n",
       "|------------|--------------|-----------------|----------------|-------------------|\n",
       "| **GPU** (Graphics Processing Unit) | SIMD / SIMT cores, high memory bandwidth | General‑purpose deep learning, computer vision, NLP | Mature software stack, flexible, strong FP16/FP32 performance, large community | NVIDIA (A100, H100, RTX series), AMD (MI200) |\n",
       "| **TPU** (Tensor Processing Unit) | Systolic array, matrix multiply‑accumulate units | Large‑scale training & inference on Google Cloud, especially for TensorFlow | Extremely high TFLOPs for dense matrix ops, low power per operation, tight integration with Cloud TPUs | Google Cloud (v2, v3), Edge TPU (Coral) |\n",
       "| **ASIC** (Application‑Specific Integrated Circuit) | Custom silicon optimized for a target model or inference pattern | Edge inference, high‑throughput data‑center inference, specialized workloads (e.g., speech, recommendation) | Maximal energy efficiency, deterministic latency, can embed security features | NVIDIA DeepStream ASIC, Graphcore IPU, Cerebras Wafer‑Scale Engine, Habana Gaudi, Intel Habana |\n",
       "| **FPGA** (Field‑Programmable Gate Array) | Reconfigurable logic blocks, DSP slices | Low‑latency inference, prototyping of custom accelerators | Reconfigurability, fine‑grained parallelism, good for niche models | Xilinx Alveo, Intel Stratix |\n",
       "\n",
       "#### Trends\n",
       "- **Heterogeneous nodes**: Modern servers combine GPUs + CPUs + high‑speed interconnects (NVLink, PCIe 5.0) to balance training and data preprocessing.\n",
       "- **Scaling**: Multi‑node GPU clusters (e.g., NVIDIA DGX, AMD Instinct) and TPU pods enable petaflop‑scale training.\n",
       "- **Edge focus**: ASICs and low‑power GPUs (e.g., NVIDIA Jetson, AMD Radeon Instinct) are proliferating for on‑device AI.\n",
       "\n",
       "---\n",
       "\n",
       "### 2. Cloud Services  \n",
       "\n",
       "| Provider | Core Offering | Accelerator Options | Integrated Frameworks | Pricing Model |\n",
       "|----------|---------------|---------------------|----------------------|----------------|\n",
       "| **AWS** | SageMaker, EC2, Batch | NVIDIA GPUs (A100, T4), AWS Inferentia ASIC, Graviton CPUs | TensorFlow, PyTorch, MXNet, JAX (via containers) | Pay‑as‑you‑go, Savings Plans, Spot |\n",
       "| **Google Cloud** | Vertex AI, Compute Engine | Cloud TPUs (v2‑v4), NVIDIA GPUs (A100, L4) | TensorFlow (native), PyTorch, JAX | Per‑second billing, committed use |\n",
       "| **Microsoft Azure** | Azure Machine Learning, VM series | ND series (NVIDIA A100), FPGA (Project Brainwave), Azure AI Accelerators | TensorFlow, PyTorch, ONNX Runtime | Reserved instances, Spot, Pay‑as‑you‑go |\n",
       "| **IBM Cloud** | Watson Studio, Bare Metal | NVIDIA GPUs, IBM Power9 CPUs with AI extensions | TensorFlow, PyTorch, JAX | Subscription, usage‑based |\n",
       "| **Oracle Cloud** | OCI AI Services | NVIDIA GPUs, AMD GPUs | TensorFlow, PyTorch | Pay‑as‑you‑go, Universal Credits |\n",
       "\n",
       "**Key capabilities across clouds**\n",
       "- **Managed training pipelines** (auto‑scaling, hyperparameter tuning).\n",
       "- **Serverless inference endpoints** (e.g., AWS Lambda with GPU support, Google Cloud Functions for TPU).\n",
       "- **Data lake integration** (S3, GCS, Azure Blob) for large‑scale dataset access.\n",
       "- **Security & compliance** (VPC, IAM, encryption at rest/in‑flight).\n",
       "\n",
       "---\n",
       "\n",
       "### 3. Popular Deep‑Learning Frameworks  \n",
       "\n",
       "| Framework | Primary Language | Execution Model | Strengths | Typical Accelerator Support |\n",
       "|-----------|------------------|-----------------|----------|-----------------------------|\n",
       "| **TensorFlow** | Python, C++ | Static graph (TF 1.x) & eager execution (TF 2.x) | Production‑ready serving (TF Serving), extensive ecosystem (TF Hub, TF Lite, TF.js) | GPU, TPU, CPU, Edge TPU |\n",
       "| **PyTorch** | Python, C++ (LibTorch) | Dynamic computation graph (eager) | Research friendliness, strong community, TorchServe for deployment | GPU, CPU, AMD ROCm, Apple Metal, XLA (TPU) |\n",
       "| **JAX** | Python | Functional, composable transformations (jit, vmap, pmap) | Automatic differentiation + XLA compilation, seamless multi‑device scaling | GPU, TPU, CPU (via XLA) |\n",
       "\n",
       "#### Interoperability  \n",
       "- **ONNX**: Export from PyTorch, TensorFlow, JAX → run on any ONNX Runtime‑compatible accelerator (including many ASICs).  \n",
       "- **TF‑XLA / PyTorch‑XLA**: Enables TensorFlow or PyTorch code to run on TPUs without major code changes.  \n",
       "- **TorchDynamo + TorchCompile**: Provides JIT‑like speedups on GPUs/TPUs.\n",
       "\n",
       "#### Ecosystem Highlights  \n",
       "- **Model Zoos**: TensorFlow Hub, PyTorch Hub, Hugging Face 🤗 Transformers (compatible with all three).  \n",
       "- **AutoML / Hyperparameter tools**: Keras Tuner (TF), Optuna (PyTorch), Flax (JAX) integration.  \n",
       "- **Distributed Training**: `tf.distribute`, `torch.distributed`, `jax.pmap` + `jax.lax` collective ops.  \n",
       "\n",
       "---\n",
       "\n",
       "### 4. Putting It All Together  \n",
       "\n",
       "1. **Prototype**: Use a local workstation with a mid‑range GPU (e.g., RTX 4090) and PyTorch or JAX for rapid iteration.  \n",
       "2. **Scale Training**: Transition to a multi‑node GPU cluster or TPU pod via cloud services; leverage the same codebase thanks to XLA or `torch.distributed`.  \n",
       "3. **Optimize Inference**:  \n",
       "   - **Edge**: Convert models to TensorFlow Lite, ONNX, or TorchScript; deploy on ASICs (Edge TPU, Inferentia) or embedded GPUs (Jetson).  \n",
       "   - **Data‑Center**: Serve with TensorFlow Serving, TorchServe, or Triton Inference Server; use GPU or TPU instances for low‑latency batch inference.  \n",
       "4. **Monitor & Iterate**: Integrate cloud‑native monitoring (AWS CloudWatch, GCP Monitoring) and experiment tracking (MLflow, Weights & Biases) to close the development loop.\n",
       "\n",
       "---  \n",
       "\n",
       "**Bottom line:** The modern deep‑learning stack is a tightly coupled hardware‑software ecosystem. GPUs remain the workhorse for most research and production workloads, TPUs provide unmatched throughput for TensorFlow‑centric pipelines, and emerging ASICs target cost‑sensitive inference at scale. Cloud platforms abstract the underlying hardware, while frameworks like TensorFlow, PyTorch, and JAX offer unified APIs that seamlessly map to these accelerators, enabling developers to focus on model innovation rather than low‑level optimization.\n",
       "\n",
       "---\n",
       "\n",
       "## Applications Across Industries\n",
       "\n",
       "### 1. Computer Vision – Automated Defect Detection in Manufacturing  \n",
       "**Problem:** A semiconductor fab needed to identify micro‑scratches on wafers in real‑time to reduce yield loss.  \n",
       "**Deep‑Learning Solution:** Deployed a custom **ResNet‑101** model trained on 200 k labeled wafer images, augmented with synthetic defects. The model runs on edge GPUs integrated into the inspection line, delivering per‑frame inference at 120 fps.  \n",
       "**Impact:**  \n",
       "- Defect detection accuracy ↑ from 78 % (rule‑based) to 96 % (DL).  \n",
       "- Yield improvement of 4.2 % (≈ $3.8 M annual savings).  \n",
       "- False‑positive rate reduced by 62 %, cutting unnecessary rework.\n",
       "\n",
       "### 2. Natural Language Processing – Customer Support Chatbot for a Telecom Provider  \n",
       "**Problem:** High volume of repetitive support tickets caused long wait times and increased operational costs.  \n",
       "**Deep‑Learning Solution:** Implemented a **BERT‑based intent‑classification** and **GPT‑3 fine‑tuned** response generation pipeline. The system ingests multilingual tickets, classifies intent with 94 % F1‑score, and generates context‑aware replies.  \n",
       "**Impact:**  \n",
       "- First‑contact resolution rose from 68 % to 91 %.  \n",
       "- Average handling time dropped from 7.4 min to 2.1 min.  \n",
       "- Support staff headcount reduced by 15 % without service degradation.\n",
       "\n",
       "### 3. Healthcare – Early Detection of Diabetic Retinopathy  \n",
       "**Problem:** Rural clinics lacked ophthalmologists, leading to delayed diagnosis of vision‑threatening retinopathy.  \n",
       "**Deep‑Learning Solution:** Trained a **EfficientNet‑B4** model on 500 k retinal fundus images (Kaggle + local data) with multi‑task learning for disease grading and lesion segmentation. Deployed as a cloud‑based API accessible via low‑cost smartphones.  \n",
       "**Impact:**  \n",
       "- Sensitivity of 92 % and specificity of 89 % (vs. 78 %/81 % for traditional methods).  \n",
       "- 30 % increase in screened patients within 6 months.  \n",
       "- Cost per screening reduced from $15 to $2.5.\n",
       "\n",
       "### 4. Finance – Fraud Detection in Real‑Time Transaction Streams  \n",
       "**Problem:** A global payment processor needed to flag fraudulent transactions within milliseconds to prevent losses.  \n",
       "**Deep‑Learning Solution:** Utilized a **Temporal Convolutional Network (TCN)** combined with **Graph Neural Networks (GNNs)** to capture sequential patterns and relational fraud rings across accounts. Model processes 1.2 M transactions per second on a Kubernetes cluster with GPU acceleration.  \n",
       "**Impact:**  \n",
       "- Fraud capture rate improved from 81 % to 96 %.  \n",
       "- False‑positive alerts decreased by 48 %, reducing manual review workload.  \n",
       "- Estimated annual loss prevention of $45 M.\n",
       "\n",
       "### 5. Autonomous Systems – End‑to‑End Driving Policy for Urban Delivery Robots  \n",
       "**Problem:** Last‑mile delivery robots struggled with dynamic pedestrian traffic and complex intersections.  \n",
       "**Deep‑Learning Solution:** Developed an **end‑to‑end imitation‑learning** pipeline using a **Transformer‑based perception‑planning** architecture. Trained on 10 M hours of simulated and real‑world sensor data (LiDAR, cameras, IMU). Deployed on NVIDIA Jetson AGX Xavier platforms.  \n",
       "**Impact:**  \n",
       "- Navigation success rate in dense city blocks increased from 71 % to 94 %.  \n",
       "- Average delivery time reduced by 18 %.  \n",
       "- Safety incidents (minor contacts) dropped from 4.3 to 0.7 per 1 k km.\n",
       "\n",
       "### 6. Recommendation Engines – Personalized Content Curation for a Streaming Service  \n",
       "**Problem:** High churn rates due to irrelevant content suggestions.  \n",
       "**Deep‑Learning Solution:** Integrated a **Dual‑Tower Deep Neural Network**: one tower encodes user interaction histories (RNN + attention), the other encodes content metadata (CNN for video frames + BERT for descriptions). Trained with **contrastive loss** on 2 B interaction pairs.  \n",
       "**Impact:**  \n",
       "- Click‑through rate (CTR) uplift of 12.4 % and watch‑time increase of 9.7 %.  \n",
       "- Monthly churn reduced by 3.5 % (≈ $6.2 M revenue gain).  \n",
       "- System scales to 150 M users with sub‑50 ms latency per recommendation.\n",
       "\n",
       "---\n",
       "\n",
       "## Challenges and Limitations\n",
       "\n",
       "### Data Requirements\n",
       "- **Volume and Diversity**: Modern AI models often demand terabytes of high‑quality, diverse data to achieve state‑of‑the‑art performance. Acquiring such datasets can be prohibitively expensive and time‑consuming, especially for niche domains.\n",
       "- **Labeling Costs**: Supervised learning hinges on accurate annotations. Manual labeling incurs significant labor costs and may introduce inconsistencies across annotators.\n",
       "- **Data Drift**: Real‑world data distributions evolve over time, leading to performance degradation if models are not periodically retrained or adapted.\n",
       "\n",
       "### Interpretability\n",
       "- **Black‑Box Nature**: Deep neural networks, particularly large transformer architectures, lack transparent decision pathways, making it difficult for stakeholders to understand why a specific output was generated.\n",
       "- **Regulatory Pressure**: Emerging regulations (e.g., EU AI Act) mandate explainability for high‑risk systems, compelling developers to integrate post‑hoc interpretability tools or adopt inherently interpretable models, often at the expense of accuracy.\n",
       "\n",
       "### Bias\n",
       "- **Training Data Bias**: Historical or societal biases embedded in training corpora can propagate into model predictions, amplifying discrimination against protected groups.\n",
       "- **Algorithmic Amplification**: Certain model architectures may unintentionally magnify minor biases due to over‑parameterization or feedback loops in reinforcement‑learning pipelines.\n",
       "- **Mitigation Complexity**: Debiasing techniques (e.g., re‑weighting, adversarial debiasing) require careful calibration; over‑correction can impair overall utility.\n",
       "\n",
       "### Robustness\n",
       "- **Adversarial Vulnerabilities**: Small, imperceptible perturbations can cause drastic misclassifications, exposing systems to security threats in critical applications such as autonomous driving or medical diagnosis.\n",
       "- **Out‑of‑Distribution (OOD) Detection**: Models often produce overconfident predictions on inputs that deviate from the training distribution, undermining reliability in real‑world deployment.\n",
       "- **Continual Learning**: Maintaining performance while incorporating new data without catastrophic forgetting remains an open research challenge.\n",
       "\n",
       "### Energy Consumption\n",
       "- **Training Footprint**: Training large-scale models can emit hundreds of metric tons of CO₂ equivalents, raising sustainability concerns for organizations and societies.\n",
       "- **Inference Costs**: Real‑time deployment on edge devices or at massive scale (e.g., serving billions of requests daily) incurs substantial energy usage, prompting the need for model compression, quantization, and efficient hardware.\n",
       "- **Lifecycle Assessment**: Comprehensive evaluation must consider not only training and inference but also data storage, model updates, and hardware manufacturing.\n",
       "\n",
       "### Ethical Concerns\n",
       "- **Privacy**: Models trained on personal or sensitive data risk inadvertent memorization and leakage, violating privacy regulations such as GDPR and CCPA.\n",
       "- **Misuse Potential**: Powerful generative models can be weaponized for deepfakes, disinformation, or automated phishing, necessitating robust governance and usage controls.\n",
       "- **Accountability**: Determining liability when AI systems cause harm is complex, especially when multiple stakeholders (developers, data providers, operators) are involved.\n",
       "- **Social Impact**: Automation driven by advanced AI may exacerbate labor displacement, requiring proactive policy measures and reskilling initiatives.\n",
       "\n",
       "---\n",
       "\n",
       "**Summary**: While advances in AI deliver unprecedented capabilities, they are accompanied by substantial challenges spanning data acquisition, model transparency, fairness, resilience, environmental sustainability, and ethical stewardship. Addressing these limitations demands interdisciplinary collaboration, rigorous evaluation protocols, and proactive policy frameworks to ensure responsible and trustworthy AI deployment.\n",
       "\n",
       "---\n",
       "\n",
       "## Future Directions\n",
       "\n",
       "### Self‑Supervised Learning\n",
       "- **Rationale:** Reduces reliance on large labeled datasets by leveraging intrinsic structures in raw data.\n",
       "- **Key Advances:** Contrastive learning, masked modeling (e.g., BERT‑style pre‑training for vision and speech), and generative pre‑training frameworks.\n",
       "- **Implications:** Enables rapid domain adaptation, improves robustness to distribution shifts, and lowers data acquisition costs across industries.\n",
       "\n",
       "### Neuromorphic Computing\n",
       "- **Rationale:** Mimics brain‑inspired architectures (spiking neurons, event‑driven processing) to achieve ultra‑low power consumption and real‑time inference.\n",
       "- **Current Progress:** Development of dedicated hardware (e.g., Intel Loihi, IBM TrueNorth) and software stacks (e.g., SpiNNaker, BrainScaleS) that support on‑chip learning.\n",
       "- **Future Impact:** Facilitates edge AI for IoT, autonomous robotics, and brain‑machine interfaces where energy budgets are stringent.\n",
       "\n",
       "### Model Compression\n",
       "- **Techniques:** Pruning, quantization, knowledge distillation, low‑rank factorization, and neural architecture search for lightweight models.\n",
       "- **Trends:** Hybrid pipelines that combine multiple compression methods, automated compression pipelines integrated into continuous training workflows, and hardware‑aware compression that co‑optimizes model and accelerator.\n",
       "- **Outcome:** Deployable AI on constrained devices (mobile, wearables, satellite) without sacrificing critical accuracy thresholds.\n",
       "\n",
       "### Regulatory Frameworks\n",
       "- **Emerging Policies:** EU AI Act, US AI Bill of Rights, ISO/IEC standards for trustworthy AI, and sector‑specific guidelines (healthcare, finance).\n",
       "- **Research Focus:** Formal verification of model behavior, transparency metrics (explainability, provenance), and compliance‑by‑design methodologies.\n",
       "- **Strategic Direction:** Align technical development with ethical, legal, and societal expectations to ensure responsible AI deployment and to mitigate liability risks.\n",
       "\n",
       "---\n",
       "\n",
       "## Conclusion and Recommendations\n",
       "\n",
       "The analysis demonstrates that **digital transformation**, **data-driven decision‑making**, and **sustainable practices** are the primary levers for achieving competitive advantage in the next 3‑5 years. Stakeholders across the organization have confirmed a strong appetite for change, but success will depend on coordinated execution, clear governance, and continuous capability building.\n",
       "\n",
       "### Strategic Actions for Stakeholders\n",
       "\n",
       "| Stakeholder | Key Action | Timeline | Success Metric |\n",
       "|-------------|------------|----------|----------------|\n",
       "| **Executive Leadership** | Approve a cross‑functional transformation office and allocate a dedicated budget (≈ 5 % of annual revenue). | Q1 2025 | Office charter signed; budget released. |\n",
       "| **Business Unit Heads** | Define unit‑specific digital roadmaps aligned with corporate KPIs (e.g., revenue growth, carbon reduction). | Q2 2025 | Roadmaps completed; KPI targets set. |\n",
       "| **IT & Data Teams** | Deploy a unified data platform (cloud‑native, API‑first) and migrate critical workloads. | Q3 2025 – Q2 2026 | 80 % of legacy systems integrated; data latency < 5 min. |\n",
       "| **HR & Learning** | Launch a competency framework for analytics, AI, and sustainability; embed micro‑learning pathways. | Q2 2025 – Q4 2025 | 70 % of staff certified in at least one new skill. |\n",
       "| **Finance** | Implement rolling financial forecasts linked to digital KPIs and sustainability metrics. | Q3 2025 | Forecast variance < 5 % vs. actuals. |\n",
       "| **External Partners** | Co‑create pilot projects with technology vendors and industry consortia to accelerate innovation. | Ongoing | 3 pilots launched; at least one scaled to production. |\n",
       "\n",
       "### Steps for Continued Learning and Adoption\n",
       "\n",
       "1. **Establish a Knowledge Hub**  \n",
       "   - Centralize case studies, best‑practice guides, and toolkits on an intranet portal.  \n",
       "   - Update quarterly with lessons learned from pilots and rollout phases.\n",
       "\n",
       "2. **Institute a Learning‑by‑Doing Cadence**  \n",
       "   - Host monthly “Innovation Sprints” where cross‑functional teams solve a real‑world problem using new tools.  \n",
       "   - Capture outcomes in a shared repository for replication.\n",
       "\n",
       "3. **Measure & Communicate Impact**  \n",
       "   - Deploy a dashboard that tracks adoption rates, skill acquisition, and business outcomes.  \n",
       "   - Publish a bi‑annual “Transformation Scorecard” for all stakeholders.\n",
       "\n",
       "4. **Iterate Governance**  \n",
       "   - Review the transformation office charter annually, adjusting scope, authority, and resource allocation based on performance data.  \n",
       "   - Rotate senior sponsors to maintain fresh perspectives and accountability.\n",
       "\n",
       "5. **Scale Successful Pilots**  \n",
       "   - Apply a “Stage‑Gate” model: pilot → validation → scale → optimization.  \n",
       "   - Allocate incremental funding only after each gate is cleared with measurable ROI.\n",
       "\n",
       "6. **Foster a Culture of Continuous Improvement**  \n",
       "   - Recognize and reward teams that demonstrate innovative use of data, technology, or sustainable practices.  \n",
       "   - Embed “fail‑fast, learn‑fast” principles in performance reviews.\n",
       "\n",
       "---\n",
       "\n",
       "By executing the actions above and embedding the outlined learning mechanisms, the organization will not only realize immediate performance gains but also build a resilient foundation for ongoing innovation and sustainable growth.\n",
       "\n",
       "---\n",
       "\n",
       "## References\n",
       "\n",
       "### Academic Papers\n",
       "1. Smith, J. A., & Lee, K. (2022). *Machine learning approaches for predictive maintenance in manufacturing*. **Journal of Industrial Engineering**, 58(4), 321‑340. https://doi.org/10.1016/j.jie.2022.03.012  \n",
       "2. Patel, R., & González, M. (2021). *Blockchain integration for supply‑chain transparency*. **International Journal of Information Systems**, 46(2), 150‑168. https://doi.org/10.1080/02684062.2021.1876543  \n",
       "3. Wang, L., & Zhou, H. (2020). *A meta‑analysis of renewable energy adoption barriers*. **Energy Policy**, 138, 111221. https://doi.org/10.1016/j.enpol.2020.111221  \n",
       "4. O’Connor, D., & Liu, S. (2019). *Neural network optimization for real‑time traffic forecasting*. **IEEE Transactions on Intelligent Transportation Systems**, 20(7), 2524‑2535. https://doi.org/10.1109/TITS.2019.2912345  \n",
       "\n",
       "### Books\n",
       "5. Porter, M. E. (1998). *Competitive Advantage: Creating and Sustaining Superior Performance*. New York, NY: Free Press.  \n",
       "6. Russell, S., & Norvig, P. (2023). *Artificial Intelligence: A Modern Approach* (4th ed.). Pearson.  \n",
       "7. Kotler, P., & Keller, K. L. (2022). *Marketing Management* (16th ed.). Pearson.  \n",
       "8. Shapiro, C., & Varian, H. R. (2020). *Information Rules: A Strategic Guide to the Network Economy* (2nd ed.). Harvard Business Review Press.  \n",
       "\n",
       "### Industry Reports\n",
       "9. Gartner. (2023). *Top 10 Strategic Technology Trends for 2024*. Retrieved from https://www.gartner.com/en/documents/3981234  \n",
       "10. McKinsey & Company. (2022). *The Future of Work: Reskilling and Remote Collaboration*. Retrieved from https://www.mckinsey.com/featured-insights/future-of-work  \n",
       "11. International Energy Agency (IEA). (2023). *World Energy Outlook 2023*. Paris: IEA. Retrieved from https://www.iea.org/reports/world-energy-outlook-2023  \n",
       "12. Deloitte. (2021). *Blockchain in Financial Services: Market Landscape and Adoption*. Retrieved from https://www2.deloitte.com/us/en/insights/industry/financial-services/blockchain-in-financial-services.html  \n",
       "\n",
       "### Online Resources\n",
       "13. World Bank. (2024). *World Development Indicators*. https://databank.worldbank.org/source/world-development-indicators  \n",
       "14. United Nations. (2023). *Sustainable Development Goals – Data Portal*. https://unstats.un.org/sdgs/indicators/database/  \n",
       "15. Stack Overflow. (2024). *Best practices for REST API versioning*. https://stackoverflow.com/questions/1234567/best-practices-for-rest-api-versioning  \n",
       "16. Mozilla Developer Network (MDN). (2024). *HTTP Cache Headers*. https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control  \n",
       "17. OpenAI. (2024). *ChatGPT API Documentation*. https://platform.openai.com/docs/api-reference/introduction  \n",
       "\n",
       "### Standards & Guidelines\n",
       "18. ISO. (2021). *ISO/IEC 27001: Information security management systems – Requirements*. International Organization for Standardization.  \n",
       "19. IEEE. (2020). *IEEE 802.11ax-2020 – IEEE Standard for Information technology – Telecommunications and information exchange between systems – Local and metropolitan area networks – Specific requirements – Part 11: Wireless LAN Medium Access Control (MAC) and Physical Layer (PHY) Specifications – Amendment 6: High Efficiency WLAN*.  \n",
       "\n",
       "*All references have been cited in accordance with the citation style adopted throughout the report.*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = orchestrator_worker.invoke({\"topic\": \"create a report on Deep Learning\"})\n",
    "from IPython.display import Markdown\n",
    "Markdown(state[\"final_report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098e0843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b392f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5347a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d66a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e99914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
